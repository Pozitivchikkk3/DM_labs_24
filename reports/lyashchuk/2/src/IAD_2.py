import numpy as np
import matplotlib.pyplot as plt
from ucimlrepo import fetch_ucirepo
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Model

# üéØ 1. –ó–ê–ì–†–£–ó–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•
print("1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö Breast Cancer Wisconsin...")

# –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)
X = breast_cancer_wisconsin_diagnostic.data.features
y = breast_cancer_wisconsin_diagnostic.data.targets

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º y –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç (M -> 1, B -> 0)
y = y.iloc[:, 0].map({'M': 1, 'B': 0}).values

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
scaler = StandardScaler()
X_normalized = scaler.fit_transform(X)

print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: {X.shape}")
print(f"–ö–ª–∞—Å—Å—ã: {np.unique(y)} (0 - Benign, 1 - Malignant)")
print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(y)}, –î–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö: {np.sum(y==0)}, –ó–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö: {np.sum(y==1)}")

# üéØ 2. –ê–í–¢–û–≠–ù–ö–û–î–ï–† –° 2 –ù–ï–ô–†–û–ù–ê–ú–ò –í –°–†–ï–î–ù–ï–ú –°–õ–û–ï
print("\n2. –°–æ–∑–¥–∞–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ —Å 2 –Ω–µ–π—Ä–æ–Ω–∞–º–∏...")

# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞
input_dim = X_normalized.shape[1]

# –≠–Ω–∫–æ–¥–µ—Ä
input_layer = keras.Input(shape=(input_dim,))
encoded = layers.Dense(128, activation='relu')(input_layer)
encoded = layers.Dense(64, activation='relu')(encoded)
encoded = layers.Dense(32, activation='relu')(encoded)
bottleneck_2d = layers.Dense(2, activation='linear', name='bottleneck_2d')(encoded)  # 2 –Ω–µ–π—Ä–æ–Ω–∞

# –î–µ–∫–æ–¥–µ—Ä
decoded = layers.Dense(32, activation='relu')(bottleneck_2d)
decoded = layers.Dense(64, activation='relu')(decoded)
decoded = layers.Dense(128, activation='relu')(decoded)
decoded = layers.Dense(input_dim, activation='linear')(decoded)

autoencoder_2d = Model(input_layer, decoded)
autoencoder_2d.compile(optimizer='adam', loss='mse')

print(autoencoder_2d.summary())

# –û–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞
print("–û–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ 2D...")
history_2d = autoencoder_2d.fit(
    X_normalized, X_normalized,
    epochs=100,
    batch_size=32,
    shuffle=True,
    validation_split=0.2,
    verbose=1
)

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —ç–Ω–∫–æ–¥–µ—Ä–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
encoder_2d = Model(input_layer, bottleneck_2d)
X_encoded_2d = encoder_2d.predict(X_normalized)

# üéØ 3. –ê–í–¢–û–≠–ù–ö–û–î–ï–† –° 3 –ù–ï–ô–†–û–ù–ê–ú–ò –í –°–†–ï–î–ù–ï–ú –°–õ–û–ï
print("\n3. –°–æ–∑–¥–∞–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ —Å 3 –Ω–µ–π—Ä–æ–Ω–∞–º–∏...")

# –≠–Ω–∫–æ–¥–µ—Ä –¥–ª—è 3D
input_layer_3d = keras.Input(shape=(input_dim,))
encoded_3d = layers.Dense(128, activation='relu')(input_layer_3d)
encoded_3d = layers.Dense(64, activation='relu')(encoded_3d)
encoded_3d = layers.Dense(32, activation='relu')(encoded_3d)
bottleneck_3d = layers.Dense(3, activation='linear', name='bottleneck_3d')(encoded_3d)  # 3 –Ω–µ–π—Ä–æ–Ω–∞

# –î–µ–∫–æ–¥–µ—Ä
decoded_3d = layers.Dense(32, activation='relu')(bottleneck_3d)
decoded_3d = layers.Dense(64, activation='relu')(decoded_3d)
decoded_3d = layers.Dense(128, activation='relu')(decoded_3d)
decoded_3d = layers.Dense(input_dim, activation='linear')(decoded_3d)

autoencoder_3d = Model(input_layer_3d, decoded_3d)
autoencoder_3d.compile(optimizer='adam', loss='mse')

print("–û–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ 3D...")
history_3d = autoencoder_3d.fit(
    X_normalized, X_normalized,
    epochs=100,
    batch_size=32,
    shuffle=True,
    validation_split=0.2,
    verbose=1
)

# –ú–æ–¥–µ–ª—å —ç–Ω–∫–æ–¥–µ—Ä–∞ –¥–ª—è 3D
encoder_3d = Model(input_layer_3d, bottleneck_3d)
X_encoded_3d = encoder_3d.predict(X_normalized)

# üéØ 4. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ê–í–¢–û–≠–ù–ö–û–î–ï–†–û–í
print("\n4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–≤...")

fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 2D –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä
scatter_2d = axes[0, 0].scatter(X_encoded_2d[:, 0], X_encoded_2d[:, 1], c=y, cmap='viridis', alpha=0.7)
axes[0, 0].set_title('–ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä - 2D –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ')
axes[0, 0].set_xlabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
axes[0, 0].set_ylabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')
plt.colorbar(scatter_2d, ax=axes[0, 0])

# 3D –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä
ax_3d = fig.add_subplot(2, 2, 2, projection='3d')
scatter_3d = ax_3d.scatter(X_encoded_3d[:, 0], X_encoded_3d[:, 1], X_encoded_3d[:, 2],
                           c=y, cmap='viridis', alpha=0.7)
ax_3d.set_title('–ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä - 3D –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ')
ax_3d.set_xlabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
ax_3d.set_ylabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')
ax_3d.set_zlabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 3')

# –ü–æ—Ç–µ—Ä–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ (2D)
axes[1, 0].plot(history_2d.history['loss'], label='–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è')
axes[1, 0].plot(history_2d.history['val_loss'], label='–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏')
axes[1, 0].set_title('–û–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ 2D')
axes[1, 0].set_xlabel('–≠–ø–æ—Ö–∞')
axes[1, 0].set_ylabel('–ü–æ—Ç–µ—Ä–∏')
axes[1, 0].legend()

# –ü–æ—Ç–µ—Ä–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ (3D)
axes[1, 1].plot(history_3d.history['loss'], label='–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è')
axes[1, 1].plot(history_3d.history['val_loss'], label='–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏')
axes[1, 1].set_title('–û–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ 3D')
axes[1, 1].set_xlabel('–≠–ø–æ—Ö–∞')
axes[1, 1].set_ylabel('–ü–æ—Ç–µ—Ä–∏')
axes[1, 1].legend()

plt.tight_layout()
plt.show()

# üéØ 5. t-SNE –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
print("\n5. t-SNE –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å —Ä–∞–∑–Ω–æ–π –ø–µ—Ä–ø–ª–µ–∫—Å–∏–≤–Ω–æ—Å—Ç—å—é...")

perplexities = [20, 35, 50, 60]
fig, axes = plt.subplots(2, 4, figsize=(20, 10))

for i, perplexity in enumerate(perplexities):
    # t-SNE —Å 2 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
    tsne_2d = TSNE(n_components=2, perplexity=perplexity, init='pca', random_state=42)
    X_tsne_2d = tsne_2d.fit_transform(X_normalized)

    # t-SNE —Å 3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
    tsne_3d = TSNE(n_components=3, perplexity=perplexity, init='pca', random_state=42)
    X_tsne_3d = tsne_3d.fit_transform(X_normalized)

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 2D
    scatter_2d = axes[0, i].scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=y, cmap='viridis', alpha=0.7)
    axes[0, i].set_title(f't-SNE 2D (perplexity={perplexity})')
    axes[0, i].set_xlabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
    axes[0, i].set_ylabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 3D
    ax_3d = fig.add_subplot(2, 4, i + 5, projection='3d')
    scatter_3d = ax_3d.scatter(X_tsne_3d[:, 0], X_tsne_3d[:, 1], X_tsne_3d[:, 2],
                               c=y, cmap='viridis', alpha=0.7)
    ax_3d.set_title(f't-SNE 3D (perplexity={perplexity})')
    ax_3d.set_xlabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
    ax_3d.set_ylabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')
    ax_3d.set_zlabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 3')

plt.tight_layout()
plt.show()

# üéØ 6. PCA –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
print("\n6. PCA –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è...")

# PCA —Å 2 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
pca_2d = PCA(n_components=2)
X_pca_2d = pca_2d.fit_transform(X_normalized)

# PCA —Å 3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
pca_3d = PCA(n_components=3)
X_pca_3d = pca_3d.fit_transform(X_normalized)

print(f"–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è PCA 2D: {pca_2d.explained_variance_ratio_.sum():.3f}")
print(f"–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è PCA 3D: {pca_3d.explained_variance_ratio_.sum():.3f}")

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# PCA 2D
scatter_pca_2d = axes[0].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=y, cmap='viridis', alpha=0.7)
axes[0].set_title('PCA - 2D –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ')
axes[0].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.2%})')
axes[0].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.2%})')
plt.colorbar(scatter_pca_2d, ax=axes[0])

# PCA 3D
ax_pca_3d = fig.add_subplot(1, 2, 2, projection='3d')
scatter_pca_3d = ax_pca_3d.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2],
                                   c=y, cmap='viridis', alpha=0.7)
ax_pca_3d.set_title('PCA - 3D –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ')
ax_pca_3d.set_xlabel(f'PC1 ({pca_3d.explained_variance_ratio_[0]:.2%})')
ax_pca_3d.set_ylabel(f'PC2 ({pca_3d.explained_variance_ratio_[1]:.2%})')
ax_pca_3d.set_zlabel(f'PC3 ({pca_3d.explained_variance_ratio_[2]:.2%})')

plt.tight_layout()
plt.show()

# üéØ 7. –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–ê–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
print("\n7. –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤...")

fig = plt.figure(figsize=(20, 15))

# –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä 2D
ax1 = fig.add_subplot(3, 3, 1)
scatter1 = ax1.scatter(X_encoded_2d[:, 0], X_encoded_2d[:, 1], c=y, cmap='viridis', alpha=0.7)
ax1.set_title('–ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä 2D')
ax1.set_xlabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
ax1.set_ylabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')

# –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä 3D
ax2 = fig.add_subplot(3, 3, 2, projection='3d')
scatter2 = ax2.scatter(X_encoded_3d[:, 0], X_encoded_3d[:, 1], X_encoded_3d[:, 2],
                       c=y, cmap='viridis', alpha=0.7)
ax2.set_title('–ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä 3D')

# t-SNE 2D (–ª—É—á—à–∞—è –ø–µ—Ä–ø–ª–µ–∫—Å–∏–≤–Ω–æ—Å—Ç—å)
tsne_best = TSNE(n_components=2, perplexity=35, init='pca', random_state=42)
X_tsne_best = tsne_best.fit_transform(X_normalized)
ax3 = fig.add_subplot(3, 3, 3)
scatter3 = ax3.scatter(X_tsne_best[:, 0], X_tsne_best[:, 1], c=y, cmap='viridis', alpha=0.7)
ax3.set_title('t-SNE 2D (perplexity=35)')
ax3.set_xlabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
ax3.set_ylabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')

# t-SNE 3D
tsne_3d_best = TSNE(n_components=3, perplexity=35, init='pca', random_state=42)
X_tsne_3d_best = tsne_3d_best.fit_transform(X_normalized)
ax4 = fig.add_subplot(3, 3, 4, projection='3d')
scatter4 = ax4.scatter(X_tsne_3d_best[:, 0], X_tsne_3d_best[:, 1], X_tsne_3d_best[:, 2],
                       c=y, cmap='viridis', alpha=0.7)
ax4.set_title('t-SNE 3D (perplexity=35)')

# PCA 2D
ax5 = fig.add_subplot(3, 3, 5)
scatter5 = ax5.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=y, cmap='viridis', alpha=0.7)
ax5.set_title('PCA 2D')
ax5.set_xlabel('PC1')
ax5.set_ylabel('PC2')

# PCA 3D
ax6 = fig.add_subplot(3, 3, 6, projection='3d')
scatter6 = ax6.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2],
                       c=y, cmap='viridis', alpha=0.7)
ax6.set_title('PCA 3D')

plt.tight_layout()
plt.show()

# üéØ 8. –í–´–í–û–î–´ –ò –ê–ù–ê–õ–ò–ó
print("\n" + "=" * 50)
print("–í–´–í–û–î–´ –ò –ê–ù–ê–õ–ò–ó")
print("=" * 50)

print("\n1. –ê–í–¢–û–≠–ù–ö–û–î–ï–†:")
print(f"   - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {input_dim} ‚Üí 128 ‚Üí 64 ‚Üí 32 ‚Üí 2/3 ‚Üí 32 ‚Üí 64 ‚Üí 128 ‚Üí {input_dim}")
print(f"   - –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: ReLU (—Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏), Linear (–≤—ã—Ö–æ–¥)")
print(f"   - –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: Adam")
print(f"   - –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å: MSE")

print("\n2. t-SNE:")
print(f"   - –î–∏–∞–ø–∞–∑–æ–Ω perplexity: {perplexities}")
print(f"   - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: PCA")
print(f"   - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ perplexity: 35")

print("\n3. PCA:")
print(f"   - –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è (2 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞): {pca_2d.explained_variance_ratio_.sum():.2%}")
print(f"   - –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è (3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞): {pca_3d.explained_variance_ratio_.sum():.2%}")

print("\n4. –°–†–ê–í–ù–ï–ù–ò–ï –ú–ï–¢–û–î–û–í:")
print("   - –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä: —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, —Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
print("   - t-SNE: –ª—É—á—à–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, –Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ —Å–ª–æ–∂–Ω—ã–π")
print("   - PCA: –ª–∏–Ω–µ–π–Ω—ã–π –º–µ—Ç–æ–¥, —Ö–æ—Ä–æ—à –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥–ª–æ–±–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")

print("\n–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é! ‚úì")